"""
Telegram Work Analyzer
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —á–∞—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç:
- SOP –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –ú–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
"""

import asyncio
import json
import os
from datetime import datetime, timedelta
from collections import defaultdict
from telethon import TelegramClient
from telethon.tl.types import User, Chat, Channel
import anthropic

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
API_ID = os.getenv("TELEGRAM_API_ID")
API_HASH = os.getenv("TELEGRAM_API_HASH")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
SESSION_NAME = "work_analyzer_session"

# –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞
DAYS_TO_ANALYZE = 30

# –õ–∏–º–∏—Ç—ã
MAX_MESSAGES_PER_CHAT = 500
MAX_CHATS = 50


class TelegramWorkAnalyzer:
    def __init__(self):
        self.client = TelegramClient(SESSION_NAME, API_ID, API_HASH)
        self.anthropic = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        self.my_id = None
        self.data = {
            "chats": {},
            "my_messages": [],
            "stats": defaultdict(int)
        }
    
    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram"""
        await self.client.start()
        me = await self.client.get_me()
        self.my_id = me.id
        print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω –∫–∞–∫: {me.first_name} (@{me.username})")
    
    async def collect_messages(self):
        """–°–±–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü"""
        cutoff_date = datetime.now() - timedelta(days=DAYS_TO_ANALYZE)
        
        print(f"\nüì• –°–æ–±–∏—Ä–∞—é —Å–æ–æ–±—â–µ–Ω–∏—è —Å {cutoff_date.strftime('%d.%m.%Y')}...")
        
        dialogs = await self.client.get_dialogs(limit=MAX_CHATS)
        
        for dialog in dialogs:
            entity = dialog.entity
            chat_name = self._get_chat_name(entity)
            chat_type = self._get_chat_type(entity)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–æ—Ç–æ–≤ –∏ –∫–∞–Ω–∞–ª—ã –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            if chat_type == "bot":
                continue
            
            print(f"  üìÇ {chat_name} ({chat_type})...", end=" ")
            
            messages = []
            my_messages_count = 0
            
            async for msg in self.client.iter_messages(
                entity, 
                limit=MAX_MESSAGES_PER_CHAT,
                offset_date=datetime.now()
            ):
                if msg.date.replace(tzinfo=None) < cutoff_date:
                    break
                
                if msg.text:
                    msg_data = {
                        "date": msg.date.isoformat(),
                        "text": msg.text[:1000],  # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ
                        "is_mine": msg.sender_id == self.my_id,
                        "hour": msg.date.hour
                    }
                    messages.append(msg_data)
                    
                    if msg.sender_id == self.my_id:
                        my_messages_count += 1
                        self.data["my_messages"].append({
                            "chat": chat_name,
                            "chat_type": chat_type,
                            **msg_data
                        })
            
            if messages:
                self.data["chats"][chat_name] = {
                    "type": chat_type,
                    "total_messages": len(messages),
                    "my_messages": my_messages_count,
                    "messages": messages
                }
                print(f"{len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π ({my_messages_count} –º–æ–∏—Ö)")
            else:
                print("–ø—É—Å—Ç–æ")
        
        self._calculate_stats()
        print(f"\n‚úÖ –°–æ–±—Ä–∞–Ω–æ: {len(self.data['my_messages'])} —Ç–≤–æ–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ {len(self.data['chats'])} —á–∞—Ç–∞—Ö")
    
    def _get_chat_name(self, entity):
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞"""
        if isinstance(entity, User):
            name = entity.first_name or ""
            if entity.last_name:
                name += f" {entity.last_name}"
            return name.strip() or f"User_{entity.id}"
        return getattr(entity, 'title', f"Chat_{entity.id}")
    
    def _get_chat_type(self, entity):
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —á–∞—Ç–∞"""
        if isinstance(entity, User):
            if entity.bot:
                return "bot"
            return "personal"
        elif isinstance(entity, Chat):
            return "group"
        elif isinstance(entity, Channel):
            if entity.megagroup:
                return "supergroup"
            return "channel"
        return "unknown"
    
    def _calculate_stats(self):
        """–ü–æ–¥—Å—á—ë—Ç –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats = self.data["stats"]
        
        for msg in self.data["my_messages"]:
            stats["total_my_messages"] += 1
            stats[f"type_{msg['chat_type']}"] += 1
            stats[f"hour_{msg['hour']}"] += 1
        
        # –¢–æ–ø —á–∞—Ç–æ–≤ –ø–æ –º–æ–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        chat_activity = {}
        for chat_name, chat_data in self.data["chats"].items():
            chat_activity[chat_name] = chat_data["my_messages"]
        
        stats["top_chats"] = dict(
            sorted(chat_activity.items(), key=lambda x: x[1], reverse=True)[:10]
        )
    
    def analyze_with_claude(self):
        """–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Claude API"""
        print("\nüß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å –ø–æ–º–æ—â—å—é Claude...")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_data = self._prepare_analysis_data()
        
        prompt = f"""–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–∞–º. 
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–æ—é —Ä–∞–±–æ—á—É—é –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—é –≤ Telegram –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü.

## –î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- –í—Å–µ–≥–æ –º–æ–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {self.data['stats']['total_my_messages']}
- –í –ª–∏—á–Ω—ã—Ö —á–∞—Ç–∞—Ö: {self.data['stats'].get('type_personal', 0)}
- –í –≥—Ä—É–ø–ø–∞—Ö: {self.data['stats'].get('type_group', 0) + self.data['stats'].get('type_supergroup', 0)}

### –¢–æ–ø —á–∞—Ç–æ–≤ –ø–æ –º–æ–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
{json.dumps(self.data['stats']['top_chats'], indent=2, ensure_ascii=False)}

### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —á–∞—Å–∞–º
{self._format_hourly_stats()}

### –ü—Ä–∏–º–µ—Ä—ã –º–æ–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (—Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —á–∞—Ç–∞–º)
{analysis_data}

---

## –ó–ê–î–ê–ß–ê

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á—ë—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:

```json
{{
  "executive_summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
  
  "time_analysis": {{
    "peak_hours": ["—á–∞—Å—ã –Ω–∞–∏–±–æ–ª—å—à–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"],
    "wasted_time_patterns": ["–ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ—Ç–µ—Ä–∏ –≤—Ä–µ–º–µ–Ω–∏"],
    "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–∞–π–º-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç—É"]
  }},
  
  "delegation_opportunities": [
    {{
      "task": "–Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏",
      "current_time_spent": "–æ—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏",
      "can_delegate_to": "–∫–æ–º—É –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å",
      "priority": "high/medium/low"
    }}
  ],
  
  "sop_candidates": [
    {{
      "process_name": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞",
      "description": "–ß—Ç–æ —ç—Ç–æ –∑–∞ –ø—Ä–æ—Ü–µ—Å—Å",
      "steps": ["—à–∞–≥ 1", "—à–∞–≥ 2", "..."],
      "triggers": "–∫–æ–≥–¥–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è",
      "owner": "–∫—Ç–æ –¥–æ–ª–∂–µ–Ω –≤—ã–ø–æ–ª–Ω—è—Ç—å",
      "tools_needed": ["–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã"]
    }}
  ],
  
  "communication_patterns": {{
    "repetitive_explanations": ["—á—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—à—å –ø–æ–≤—Ç–æ—Ä–Ω–æ"],
    "bottlenecks": ["–≥–¥–µ –∑–∞—Å—Ç—Ä–µ–≤–∞—é—Ç –ø—Ä–æ—Ü–µ—Å—Å—ã"],
    "improvements": ["–∫–∞–∫ —É–ª—É—á—à–∏—Ç—å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—é"]
  }},
  
  "automation_ideas": [
    {{
      "idea": "—á—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å",
      "impact": "high/medium/low",
      "implementation": "–∫–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å"
    }}
  ],
  
  "metrics": {{
    "operational_vs_strategic": "X% / Y%",
    "response_time_estimate": "–æ—Ü–µ–Ω–∫–∞",
    "context_switching": "–æ—Ü–µ–Ω–∫–∞ —á–∞—Å—Ç–æ—Ç—ã –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π"
  }},
  
  "action_plan": [
    {{
      "action": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ",
      "priority": 1,
      "expected_result": "–æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"
    }}
  ]
}}
```

–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º. –ù–∞–∑—ã–≤–∞–π —Ä–µ–∞–ª—å–Ω—ã–µ —á–∞—Ç—ã –∏ –∑–∞–¥–∞—á–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö.
–§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ actionable insights, –∞ –Ω–µ –æ–±—â–∏—Ö —Å–æ–≤–µ—Ç–∞—Ö.
"""

        response = self.anthropic.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=8000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return self._parse_claude_response(response.content[0].text)
    
    def _prepare_analysis_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Claude"""
        result = []
        
        for chat_name, chat_data in self.data["chats"].items():
            my_msgs = [m for m in chat_data["messages"] if m["is_mine"]]
            if not my_msgs:
                continue
            
            # –ë–µ—Ä—ë–º sample —Å–æ–æ–±—â–µ–Ω–∏–π
            sample = my_msgs[:30] if len(my_msgs) > 30 else my_msgs
            
            result.append(f"\n### {chat_name} ({chat_data['type']}) ‚Äî {len(my_msgs)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            for msg in sample:
                date = msg["date"][:10]
                result.append(f"[{date}] {msg['text'][:200]}")
        
        return "\n".join(result)[:50000]  # –õ–∏–º–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    
    def _format_hourly_stats(self):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —á–∞—Å–∞–º"""
        hours = {}
        for key, value in self.data["stats"].items():
            if key.startswith("hour_"):
                hour = int(key.split("_")[1])
                hours[hour] = value
        
        result = []
        for hour in sorted(hours.keys()):
            bar = "‚ñà" * (hours[hour] // 5)
            result.append(f"{hour:02d}:00 ‚Äî {hours[hour]:3d} {bar}")
        
        return "\n".join(result)
    
    def _parse_claude_response(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ Claude"""
        try:
            # –ò—â–µ–º JSON –±–ª–æ–∫
            start = text.find("{")
            end = text.rfind("}") + 1
            if start != -1 and end > start:
                return json.loads(text[start:end])
        except json.JSONDecodeError:
            pass
        
        return {"raw_response": text}
    
    def generate_reports(self, analysis):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤"""
        print("\nüìù –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á—ë—Ç—ã...")
        
        # 1. –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á—ë—Ç
        self._save_main_report(analysis)
        
        # 2. SOP –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self._save_sop_documents(analysis)
        
        # 3. Action –ø–ª–∞–Ω
        self._save_action_plan(analysis)
        
        # 4. –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        self._save_raw_data()
        
        print("\n‚úÖ –û—Ç—á—ë—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É 'reports/'")
    
    def _save_main_report(self, analysis):
        """–ì–ª–∞–≤–Ω—ã–π –æ—Ç—á—ë—Ç –≤ Markdown"""
        os.makedirs("reports", exist_ok=True)
        
        report = f"""# üìä –ê–Ω–∞–ª–∏–∑ —Ä–∞–±–æ—á–µ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
**–ü–µ—Ä–∏–æ–¥:** {DAYS_TO_ANALYZE} –¥–Ω–µ–π
**–î–∞—Ç–∞ –æ—Ç—á—ë—Ç–∞:** {datetime.now().strftime('%d.%m.%Y %H:%M')}

---

## üìã –†–µ–∑—é–º–µ

{analysis.get('executive_summary', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}

---

## ‚è∞ –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏

### –ü–∏–∫–æ–≤—ã–µ —á–∞—Å—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
{self._format_list(analysis.get('time_analysis', {}).get('peak_hours', []))}

### –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ—Ç–µ—Ä–∏ –≤—Ä–µ–º–µ–Ω–∏
{self._format_list(analysis.get('time_analysis', {}).get('wasted_time_patterns', []))}

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
{self._format_list(analysis.get('time_analysis', {}).get('recommendations', []))}

---

## üéØ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

{self._format_delegation_table(analysis.get('delegation_opportunities', []))}

---

## üí¨ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏

### –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–Ω—É–∂–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)
{self._format_list(analysis.get('communication_patterns', {}).get('repetitive_explanations', []))}

### –£–∑–∫–∏–µ –º–µ—Å—Ç–∞ (–≥–¥–µ –∑–∞—Å—Ç—Ä–µ–≤–∞—é—Ç –ø—Ä–æ—Ü–µ—Å—Å—ã)
{self._format_list(analysis.get('communication_patterns', {}).get('bottlenecks', []))}

### –ö–∞–∫ —É–ª—É—á—à–∏—Ç—å
{self._format_list(analysis.get('communication_patterns', {}).get('improvements', []))}

---

## ü§ñ –ò–¥–µ–∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏

{self._format_automation_table(analysis.get('automation_ideas', []))}

---

## üìà –ú–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–∫–∞ vs –°—Ç—Ä–∞—Ç–µ–≥–∏—è | {analysis.get('metrics', {}).get('operational_vs_strategic', 'N/A')} |
| –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ | {analysis.get('metrics', {}).get('response_time_estimate', 'N/A')} |
| –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ | {analysis.get('metrics', {}).get('context_switching', 'N/A')} |

---

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö

- **–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π:** {self.data['stats']['total_my_messages']}
- **–õ–∏—á–Ω—ã–µ —á–∞—Ç—ã:** {self.data['stats'].get('type_personal', 0)}
- **–ì—Ä—É–ø–ø—ã:** {self.data['stats'].get('type_group', 0) + self.data['stats'].get('type_supergroup', 0)}

### –¢–æ–ø-10 —á–∞—Ç–æ–≤ –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
{self._format_top_chats()}

### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —á–∞—Å–∞–º
```
{self._format_hourly_stats()}
```
"""
        
        with open("reports/main_report.md", "w", encoding="utf-8") as f:
            f.write(report)
        
        print("  ‚úì reports/main_report.md")
    
    def _save_sop_documents(self, analysis):
        """–û—Ç–¥–µ–ª—å–Ω—ã–µ SOP –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        sops = analysis.get("sop_candidates", [])
        
        if not sops:
            return
        
        os.makedirs("reports/sops", exist_ok=True)
        
        for i, sop in enumerate(sops, 1):
            filename = f"reports/sops/SOP_{i:02d}_{self._slugify(sop.get('process_name', 'process'))}.md"
            
            content = f"""# SOP: {sop.get('process_name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}

## –û–ø–∏—Å–∞–Ω–∏–µ
{sop.get('description', '')}

## –¢—Ä–∏–≥–≥–µ—Ä
{sop.get('triggers', '–ù–µ —É–∫–∞–∑–∞–Ω')}

## –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π
{sop.get('owner', '–ù–µ –Ω–∞–∑–Ω–∞—á–µ–Ω')}

## –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
{self._format_list(sop.get('tools_needed', []))}

## –®–∞–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

{self._format_numbered_list(sop.get('steps', []))}

---
*–°–æ–∑–¥–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {datetime.now().strftime('%d.%m.%Y')}*
"""
            
            with open(filename, "w", encoding="utf-8") as f:
                f.write(content)
            
            print(f"  ‚úì {filename}")
    
    def _save_action_plan(self, analysis):
        """Action –ø–ª–∞–Ω"""
        actions = analysis.get("action_plan", [])
        
        content = f"""# üéØ Action Plan
**–î–∞—Ç–∞:** {datetime.now().strftime('%d.%m.%Y')}

---

"""
        for action in actions:
            priority = action.get("priority", "?")
            content += f"""## [{priority}] {action.get('action', '–î–µ–π—Å—Ç–≤–∏–µ')}

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** {action.get('expected_result', '–ù–µ —É–∫–∞–∑–∞–Ω')}

---

"""
        
        with open("reports/action_plan.md", "w", encoding="utf-8") as f:
            f.write(content)
        
        print("  ‚úì reports/action_plan.md")
    
    def _save_raw_data(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–µ–∑ –ø–æ–ª–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        stats_only = {
            "stats": dict(self.data["stats"]),
            "chats_summary": {
                name: {
                    "type": data["type"],
                    "total": data["total_messages"],
                    "mine": data["my_messages"]
                }
                for name, data in self.data["chats"].items()
            }
        }
        
        with open("reports/stats.json", "w", encoding="utf-8") as f:
            json.dump(stats_only, f, ensure_ascii=False, indent=2)
        
        print("  ‚úì reports/stats.json")
    
    # === Helpers ===
    
    def _format_list(self, items):
        if not items:
            return "*–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö*"
        return "\n".join(f"- {item}" for item in items)
    
    def _format_numbered_list(self, items):
        if not items:
            return "*–ù–µ—Ç —à–∞–≥–æ–≤*"
        return "\n".join(f"{i}. {item}" for i, item in enumerate(items, 1))
    
    def _format_delegation_table(self, items):
        if not items:
            return "*–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö*"
        
        result = "| –ó–∞–¥–∞—á–∞ | –í—Ä–µ–º—è | –ö–æ–º—É –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |\n"
        result += "|--------|-------|-------------------|------------|\n"
        
        for item in items:
            result += f"| {item.get('task', '')} | {item.get('current_time_spent', '')} | {item.get('can_delegate_to', '')} | {item.get('priority', '')} |\n"
        
        return result
    
    def _format_automation_table(self, items):
        if not items:
            return "*–ù–µ—Ç –∏–¥–µ–π*"
        
        result = "| –ò–¥–µ—è | –ò–º–ø–∞–∫—Ç | –†–µ–∞–ª–∏–∑–∞—Ü–∏—è |\n"
        result += "|------|--------|------------|\n"
        
        for item in items:
            result += f"| {item.get('idea', '')} | {item.get('impact', '')} | {item.get('implementation', '')} |\n"
        
        return result
    
    def _format_top_chats(self):
        top = self.data["stats"].get("top_chats", {})
        return "\n".join(f"- **{name}**: {count} —Å–æ–æ–±—â–µ–Ω–∏–π" for name, count in top.items())
    
    def _slugify(self, text):
        import re
        text = text.lower().strip()
        text = re.sub(r'[^\w\s-]', '', text)
        text = re.sub(r'[\s_-]+', '_', text)
        return text[:50]
    
    async def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫"""
        print("=" * 50)
        print("üîç TELEGRAM WORK ANALYZER")
        print("=" * 50)
        
        await self.connect()
        await self.collect_messages()
        
        analysis = self.analyze_with_claude()
        self.generate_reports(analysis)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        with open("reports/full_analysis.json", "w", encoding="utf-8") as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        
        print("\n" + "=" * 50)
        print("‚úÖ –ì–û–¢–û–í–û!")
        print("=" * 50)
        print("\n–û—Ç–∫—Ä–æ–π reports/main_report.md –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞")
        print("SOP –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ reports/sops/")


async def main():
    analyzer = TelegramWorkAnalyzer()
    await analyzer.run()


if __name__ == "__main__":
    asyncio.run(main())
